# ğŸš€ High Availability Hadoop Ecosystem with HBase & Hive

This project sets up a production-grade **Hadoop ecosystem** using Docker Compose with High Availability (HA) for **HDFS**, **YARN**, **HBase**, and **Hive**, coordinated via **ZooKeeper** and backed by **PostgreSQL** for Hive Metastore.

---

## ğŸ“¦ Components Overview

| Component         | Count | Description |
|------------------|-------|-------------|
| **Hadoop NameNodes (HA)** | 3 | High-availability NameNodes with JournalNodes |
| **YARN ResourceManager** | 3 | HA Resource Managers embedded in master nodes |
| **DataNodes & NodeManagers** | 2 | Workers running DataNode & NodeManager |
| **ZooKeeper Ensemble** | 3 | One per master node for quorum management |
| **HBase Master (HA)** | 2 | Active-Standby configuration |
| **HBase RegionServers** | 2 | Storage engine for HBase |
| **Hive Metastore** | 1 | Backed by PostgreSQL |
| **HiveServer2** | 1 | Query engine for Hive |
| **PostgreSQL** | 1 | Metastore DB for Hive |

---

## ğŸ—‚ï¸ Folder Structure

```
.
â”œâ”€â”€ Dockerfile               # Multi-stage build for Hadoop, Hive, and HBase
â”œâ”€â”€ docker-compose.yaml      # Multi-container cluster orchestration
â”œâ”€â”€ start-hadoop.sh          # Entrypoint script for Hadoop services
â”œâ”€â”€ start-hbase.sh           # Entrypoint script for HBase services
â”œâ”€â”€ start-hive.sh            # Entrypoint script for Hive services
```

---

## ğŸ› ï¸ Setup Instructions

### 1. ğŸš§ Build & Start Cluster

```bash
docker-compose build
docker-compose up -d
```

Ensure all services pass their health checks.

### 2. ğŸ“Š Access Web UIs

| Service           | URL                        |
|------------------|----------------------------|
| **HDFS UI (NN1)**    | http://localhost:9878     |
| **YARN UI**          | http://localhost:8888     |
| **HiveServer2 (JDBC)** | jdbc:hive2://localhost:10000 |
| **HBase UI (HM1)**   | http://localhost:16010    |

---

## ğŸ“ Service Roles

### ğŸ§  Master Nodes
- Host **NameNode**, **ResourceManager**, and **ZooKeeper**
- JournalNode volumes for HA HDFS

### ğŸ”§ Worker Nodes
- Run **DataNode** and **NodeManager**
- Depend on all three master nodes

### ğŸ HBase
- 2 Masters (HA)
- 2 RegionServers with HDFS-backed volumes

### ğŸ˜ Hive
- **Metastore** connected to PostgreSQL
- **HiveServer2** handles queries
- Runs only after master & metastore are healthy

---

## ğŸ“„ Health Checks

Each major service (HDFS, Hive, PostgreSQL, HBase) uses Docker `healthcheck` to ensure container health before others depend on it.

---

## ğŸ” Network & Volumes

- **Network**: All containers connected through `hadoopnet` bridge
- **Volumes**: Separate persistent volumes per component

---

## ğŸ”„ Cleanup

```bash
docker-compose down -v
```

This will stop and remove all containers and volumes.

---

## ğŸ“Œ Notes

- Ensure your system has enough resources: recommended 8+ GB RAM and 4+ CPUs
- For production, use external persistent storage and real domain names/IPs

---

## ğŸ™Œ Authors

**Designed & Engineered by**: Mohamed Moaaz
Inspired by scalable Hadoop deployments for modern data platforms.
